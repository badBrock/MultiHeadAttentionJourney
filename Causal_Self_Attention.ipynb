{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBJSKOuP9MpntO65A4/219",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badBrock/MultiHeadAttentionJourney/blob/main/Causal_Self_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEtfF0szesXA"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")"
      ],
      "metadata": {
        "id": "Dz8XwiF-ewZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_query = inputs[1]\n",
        "input_query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEKAKKBGfJkq",
        "outputId": "561cc70a-1aed-4e14-9b58-29636df4ad19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5500, 0.8700, 0.6600])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_query @ inputs.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVzusmzylzpb",
        "outputId": "15027cfa-55c0-44a4-ef1f-a528ce8450c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_score2 = torch.empty(inputs.shape[0])"
      ],
      "metadata": {
        "id": "cq-3SirAgV4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(inputs)):\n",
        "  attn_score2[i] = torch.dot(input_query,inputs[i])"
      ],
      "metadata": {
        "id": "X5SVKiDyfgPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_score2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8YvkgcJgIdE",
        "outputId": "dac7e810-f42c-445a-9631-7495f17f7f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_score2,dim=0)\n",
        "attn_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K21FzoIPgO9Z",
        "outputId": "5d9d8688-3f0e-477a-b625-411e14ccc8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2 = attn_weights"
      ],
      "metadata": {
        "id": "f3h6Y4zjgtgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cxt_vector = torch.zeros(inputs.shape[1])\n",
        "for i in range(len(inputs)):\n",
        "  cxt_vector += attn_weights[i] * inputs[i]"
      ],
      "metadata": {
        "id": "emxg86hchNLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(cxt_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djnkn0Tdjsrr",
        "outputId": "c18ee64c-f673-44db-ee07-cbfdb31f9c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4419, 0.6515, 0.5683])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! now we can do this for all the values here"
      ],
      "metadata": {
        "id": "4NPJrceykpvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we have inputs\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRH1HRzLmZyS",
        "outputId": "6b06e9dc-93c8-47fa-f9bb-4644ddea728f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4300, 0.1500, 0.8900],\n",
              "        [0.5500, 0.8700, 0.6600],\n",
              "        [0.5700, 0.8500, 0.6400],\n",
              "        [0.2200, 0.5800, 0.3300],\n",
              "        [0.7700, 0.2500, 0.1000],\n",
              "        [0.0500, 0.8000, 0.5500]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to get the attn_score we do\n",
        "\n",
        "all_attn_scores = inputs @ inputs.T\n",
        "all_attn_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ_gArShmbyL",
        "outputId": "bd314b59-2269-4601-b0d7-13de8790b852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
              "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
              "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
              "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
              "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
              "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_attn_weights = torch.softmax(all_attn_scores,dim=1)\n",
        "all_attn_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG2wGA6qmuCl",
        "outputId": "af1015ea-1be9-43d5-a2b7-e25efdc985d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
              "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
              "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
              "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
              "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
              "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(all_attn_weights)):\n",
        "  print(all_attn_weights.sum(axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd0krZAjm1oA",
        "outputId": "2272423d-45d7-4ce9-f75c-70ddf2169316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_context = all_attn_weights @ inputs"
      ],
      "metadata": {
        "id": "dcPnSpx_m9-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPxmfPhWnP6p",
        "outputId": "c213fe66-db24-4456-ea80-eef036f576e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4421, 0.5931, 0.5790],\n",
              "        [0.4419, 0.6515, 0.5683],\n",
              "        [0.4431, 0.6496, 0.5671],\n",
              "        [0.4304, 0.6298, 0.5510],\n",
              "        [0.4671, 0.5910, 0.5266],\n",
              "        [0.4177, 0.6503, 0.5645]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self,d_in,d_out):\n",
        "    super().__init__()\n",
        "    # inputs dim is what his d_in is, i.e the dim we already have for our inputs\n",
        "    self.W_q = torch.nn.Linear(d_in,d_out,bias=False)\n",
        "    self.W_k = torch.nn.Linear(d_in,d_out,bias=False)\n",
        "    self.W_v = torch.nn.Linear(d_in,d_out,bias=False)\n",
        "\n",
        "  def forward(self,x):\n",
        "    self.Q = self.W_q(x)\n",
        "    self.K = self.W_q(x)\n",
        "    self.V = self.W_q(x)\n",
        "\n",
        "    attn_score = self.Q @ self.K.T\n",
        "    attn_weights = torch.softmax(attn_score,dim=1)\n",
        "\n",
        "    context_vec = attn_weights @ self.V\n",
        "\n",
        "    return context_vec\n"
      ],
      "metadata": {
        "id": "ATbJ234jnZQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl0Ar8_lUV-B",
        "outputId": "8d6c6759-e985-4886-bfd7-e91f35c8dc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "call = Attention(3,1)"
      ],
      "metadata": {
        "id": "zjBCbqTxwWkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctx = call(inputs)"
      ],
      "metadata": {
        "id": "ywErycrjwdej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3KHp7UkTsKI",
        "outputId": "659189c7-a16c-46eb-8efd-da8097b1771a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1668],\n",
              "        [0.1534],\n",
              "        [0.1537],\n",
              "        [0.1479],\n",
              "        [0.1582],\n",
              "        [0.1451]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = ctx[:5,:5]"
      ],
      "metadata": {
        "id": "An58Qe7n1BgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctx.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua1XsaRKy0Uy",
        "outputId": "c83e5962-0175-428e-b4e5-585ed1f450ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(torch.ones(ctx.shape[0], len(ctx)),diagonal=1)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSE3r5xnzbLy",
        "outputId": "590fca5b-a56f-4f69-9ab5-ebb1b08308c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ctx shape :\", ctx.shape)\n",
        "print(\"mask shape:\", mask.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfLe_owz02pO",
        "outputId": "42400890-748e-4728-c8d2-3ff467984f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ctx shape : torch.Size([6, 6])\n",
            "mask shape: torch.Size([6, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked = ctx.masked_fill(mask.bool(),-torch.inf)\n",
        "masked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4B4QGaoz8FX",
        "outputId": "ea7ab364-efef-4deb-e069-48a62ea08ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0320,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
              "        [ 0.0463,  0.1210,    -inf,    -inf,    -inf,    -inf],\n",
              "        [ 0.0465,  0.1203, -0.5353,    -inf,    -inf,    -inf],\n",
              "        [ 0.0410,  0.1110, -0.5072,  0.7491,    -inf,    -inf],\n",
              "        [ 0.0498,  0.0966, -0.5066,  0.7450,  0.4531,    -inf],\n",
              "        [ 0.0382,  0.1200, -0.5150,  0.7614,  0.4621,  0.7444]],\n",
              "       grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(masked,dim=-1)"
      ],
      "metadata": {
        "id": "SP8qAgM_0b2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2ZZzwQo1wKP",
        "outputId": "316b5914-ed65-460a-ebb8-ea2e365ba726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4814, 0.5186, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3795, 0.4085, 0.2121, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2137, 0.2291, 0.1235, 0.4337, 0.0000, 0.0000],\n",
              "        [0.1633, 0.1712, 0.0936, 0.3274, 0.2445, 0.0000],\n",
              "        [0.1208, 0.1311, 0.0695, 0.2491, 0.1846, 0.2449]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack((inputs,inputs), dim = 0)\n",
        "batch.shape"
      ],
      "metadata": {
        "id": "2jJ2sWJD1x7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871d9cd0-2210-4b21-e898-fffc52bb3300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhMocHIecVBy",
        "outputId": "3280e969-afd7-414e-9768-16ba6ddd1d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1668],\n",
              "        [0.1534],\n",
              "        [0.1537],\n",
              "        [0.1479],\n",
              "        [0.1582],\n",
              "        [0.1451]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim = ctx.shape[0]"
      ],
      "metadata": {
        "id": "F45lXt-vQOaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(torch.ones(dim,dim), diagonal=1)"
      ],
      "metadata": {
        "id": "Qi67g-CNPthP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyjcKZvKQRQc",
        "outputId": "c084ee3c-d4f2-4cbc-9ec1-aa08b9b38a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask.bool()[:6,:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhekwus5RSmj",
        "outputId": "e12f7dec-efaa-4932-8af0-02dc289c08d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  True,  True,  True],\n",
              "        [False, False,  True,  True,  True,  True],\n",
              "        [False, False, False,  True,  True,  True],\n",
              "        [False, False, False, False,  True,  True],\n",
              "        [False, False, False, False, False,  True],\n",
              "        [False, False, False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.masked_fill(mask.bool()[:5,:5], -torch.inf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOiMDdrQRP40",
        "outputId": "714316ed-10c5-488f-8edd-07c70fdce809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2173,   -inf,   -inf,   -inf,   -inf],\n",
              "        [0.1758, 0.1822,   -inf,   -inf,   -inf],\n",
              "        [0.1742, 0.1822, 0.1818,   -inf,   -inf],\n",
              "        [0.1696, 0.1749, 0.1744, 0.1593,   -inf],\n",
              "        [0.1432, 0.1744, 0.1773, 0.1520, 0.2220]],\n",
              "       grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_num, row, feature_dim = batch.shape\n",
        "out_dim = 4"
      ],
      "metadata": {
        "id": "5kvhCVb1aKvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wq = nn.Linear(feature_dim,out_dim,bias=False)\n",
        "wk = nn.Linear(feature_dim,out_dim,bias=False)\n",
        "wv = nn.Linear(feature_dim,out_dim,bias=False)"
      ],
      "metadata": {
        "id": "yhMdF9cEaMYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_projection = nn.Linear(feature_dim,out_dim)"
      ],
      "metadata": {
        "id": "k0blAytybW1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = 6"
      ],
      "metadata": {
        "id": "lnqkETbabtT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qdW9-Gdbpja",
        "outputId": "033507b4-2627-4d68-b371-50ab44b5bfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = wq(batch)\n",
        "queries = wq(batch)\n",
        "values = wv(batch)"
      ],
      "metadata": {
        "id": "sBJZXW3CceG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkm0GFj8cuLj",
        "outputId": "aa06a702-d385-42de-8334-6da689f6284d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4821,  0.4336,  0.0376,  0.2466],\n",
              "         [-0.5965,  0.6734,  0.2635,  0.1029],\n",
              "         [-0.5914,  0.6726,  0.2422,  0.1129],\n",
              "         [-0.3124,  0.3564,  0.2207, -0.0035],\n",
              "         [-0.3341,  0.4689, -0.2114,  0.2630],\n",
              "         [-0.3838,  0.3892,  0.4338, -0.0944]],\n",
              "\n",
              "        [[-0.4821,  0.4336,  0.0376,  0.2466],\n",
              "         [-0.5965,  0.6734,  0.2635,  0.1029],\n",
              "         [-0.5914,  0.6726,  0.2422,  0.1129],\n",
              "         [-0.3124,  0.3564,  0.2207, -0.0035],\n",
              "         [-0.3341,  0.4689, -0.2114,  0.2630],\n",
              "         [-0.3838,  0.3892,  0.4338, -0.0944]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O93cWBbcyaA",
        "outputId": "01671775-7102-4426-8ed1-d2f997366c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4821,  0.4336,  0.0376,  0.2466],\n",
              "         [-0.5965,  0.6734,  0.2635,  0.1029],\n",
              "         [-0.5914,  0.6726,  0.2422,  0.1129],\n",
              "         [-0.3124,  0.3564,  0.2207, -0.0035],\n",
              "         [-0.3341,  0.4689, -0.2114,  0.2630],\n",
              "         [-0.3838,  0.3892,  0.4338, -0.0944]],\n",
              "\n",
              "        [[-0.4821,  0.4336,  0.0376,  0.2466],\n",
              "         [-0.5965,  0.6734,  0.2635,  0.1029],\n",
              "         [-0.5914,  0.6726,  0.2422,  0.1129],\n",
              "         [-0.3124,  0.3564,  0.2207, -0.0035],\n",
              "         [-0.3341,  0.4689, -0.2114,  0.2630],\n",
              "         [-0.3838,  0.3892,  0.4338, -0.0944]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys.transpose(1,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgfUk_5mc-c6",
        "outputId": "501a4651-c8f5-4c58-9dc3-241b2934859e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4821, -0.5965, -0.5914, -0.3124, -0.3341, -0.3838],\n",
              "         [ 0.4336,  0.6734,  0.6726,  0.3564,  0.4689,  0.3892],\n",
              "         [ 0.0376,  0.2635,  0.2422,  0.2207, -0.2114,  0.4338],\n",
              "         [ 0.2466,  0.1029,  0.1129, -0.0035,  0.2630, -0.0944]],\n",
              "\n",
              "        [[-0.4821, -0.5965, -0.5914, -0.3124, -0.3341, -0.3838],\n",
              "         [ 0.4336,  0.6734,  0.6726,  0.3564,  0.4689,  0.3892],\n",
              "         [ 0.0376,  0.2635,  0.2422,  0.2207, -0.2114,  0.4338],\n",
              "         [ 0.2466,  0.1029,  0.1129, -0.0035,  0.2630, -0.0944]]],\n",
              "       grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = queries @ keys.transpose(1, 2)"
      ],
      "metadata": {
        "id": "ZkLSYjN4dXR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MSSV-xReSLu",
        "outputId": "dceff812-9fad-4b3d-aa3a-b56d136455c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys.view(batch_num,row,2,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNA-yhhaeTH4",
        "outputId": "df81b9c0-7317-4572-a3e4-e24e0b31b65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.4821,  0.4336],\n",
              "          [ 0.0376,  0.2466]],\n",
              "\n",
              "         [[-0.5965,  0.6734],\n",
              "          [ 0.2635,  0.1029]],\n",
              "\n",
              "         [[-0.5914,  0.6726],\n",
              "          [ 0.2422,  0.1129]],\n",
              "\n",
              "         [[-0.3124,  0.3564],\n",
              "          [ 0.2207, -0.0035]],\n",
              "\n",
              "         [[-0.3341,  0.4689],\n",
              "          [-0.2114,  0.2630]],\n",
              "\n",
              "         [[-0.3838,  0.3892],\n",
              "          [ 0.4338, -0.0944]]],\n",
              "\n",
              "\n",
              "        [[[-0.4821,  0.4336],\n",
              "          [ 0.0376,  0.2466]],\n",
              "\n",
              "         [[-0.5965,  0.6734],\n",
              "          [ 0.2635,  0.1029]],\n",
              "\n",
              "         [[-0.5914,  0.6726],\n",
              "          [ 0.2422,  0.1129]],\n",
              "\n",
              "         [[-0.3124,  0.3564],\n",
              "          [ 0.2207, -0.0035]],\n",
              "\n",
              "         [[-0.3341,  0.4689],\n",
              "          [-0.2114,  0.2630]],\n",
              "\n",
              "         [[-0.3838,  0.3892],\n",
              "          [ 0.4338, -0.0944]]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # so i finally figured out the complexity of this multi head attention and how each\n",
        "# head is able to generate differnet meaning along with why we need to have the\n",
        "# output dim = the heads\n",
        "# so what is happening is that when we decide on this output dim which is technically\n",
        "# a hyper parameter for the linear projections we inherently determine the output dim\n",
        "# now what happens is that in single head attention we get the context vector or\n",
        "# the dim of our choosing but when working with mha we work on the slices of these\n",
        "# token embeddings which is why each of the head in mha is able to generate differnet\n",
        "# output for the same input. its like defining 'i hate you' in a 768 dim vector and then\n",
        "# projection to the linear layer to get say 1024 dim and finally when we reach the mha\n",
        "# it works on all of the tokens but on the slices of the features. this is why we need\n",
        "# the head to div the output dim as we are splitting the embeddings into these heads.\n",
        "# In single-head attention, output dimension is unconstrained.\n",
        "# In multi-head attention, the chosen output dimension must be divisible by the\n",
        "# number of heads so it can be evenly split across them.\n",
        "\n",
        "# \"love\":\n",
        "# Head 1 → [f1, f2]\n",
        "# Head 2 → [f3, f4]"
      ],
      "metadata": {
        "id": "16Dd3AJAiOGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, id, od, context_win, bias=False):\n",
        "    super().__init__()\n",
        "    self.qw = nn.Linear(id,od,bias=bias)\n",
        "    self.qk = nn.Linear(id,od,bias=bias)\n",
        "    self.qv = nn.Linear(id,od,bias=bias)\n",
        "    self.register_buffer('mask',torch.triu(torch.ones(context_win,context_win),diagonal=1))\n",
        "\n",
        "  def forward(self,x):\n",
        "    b, context_win, dim_out =  x.shape\n",
        "    # here the contextwin is safety measure if we ever exceed the window which is in the batch\n",
        "    self.K = self.qk(x)\n",
        "    self.Q = self.qw(x)\n",
        "    self.V = self.qv(x)\n",
        "\n",
        "    attn_scores = self.K @ self.Q.transpose(1,2)\n",
        "    attn_scores.masked_fill_(self.mask.bool()[:context_win,:context_win],-torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / self.K.shape[0]**0.5,dim=-1)\n",
        "    context_vec = attn_weights @ self.V\n",
        "\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "zqoSpEyGgqFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this here is for just a single two dim tensor with no batch\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, id, od, context_win, bias=False):\n",
        "    super().__init__()\n",
        "    self.qw = nn.Linear(id,od,bias=bias)\n",
        "    self.qk = nn.Linear(id,od,bias=bias)\n",
        "    self.qv = nn.Linear(id,od,bias=bias)\n",
        "    self.register_buffer('mask',torch.triu(torch.ones(context_win,context_win),diagonal=1))\n",
        "\n",
        "  def forward(self,x):\n",
        "    context_win, dim_out =  x.shape\n",
        "    # here the contextwin is safety measure if we ever exceed the window which is in the batch\n",
        "    self.K = self.qk(x)\n",
        "    self.Q = self.qw(x)\n",
        "    self.V = self.qv(x)\n",
        "\n",
        "    attn_scores = self.K @ self.Q.T\n",
        "    attn_scores.masked_fill_(self.mask.bool()[:context_win,:context_win],-torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / self.K.shape[0]**0.5,dim=-1)\n",
        "    context_vec = attn_weights @ self.V\n",
        "\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "aJGLqzM-8eMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPh4p9NCfX8u",
        "outputId": "62980306-3950-4205-d6aa-9224237be68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]],\n",
              "\n",
              "        [[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]]])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, rows, features = batch.shape\n",
        "print(batch_size, rows, features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcI_gn3Sc6Q0",
        "outputId": "7317fbb7-fbb3-405e-ae21-053cd0b2c963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 6 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparamter = 4"
      ],
      "metadata": {
        "id": "A_DZ16lHdbd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XINiJ4ZhYsw",
        "outputId": "ab0d83c7-e887-43c6-b332-abea212e7d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4300, 0.1500, 0.8900],\n",
              "        [0.5500, 0.8700, 0.6600],\n",
              "        [0.5700, 0.8500, 0.6400],\n",
              "        [0.2200, 0.5800, 0.3300],\n",
              "        [0.7700, 0.2500, 0.1000],\n",
              "        [0.0500, 0.8000, 0.5500]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# features are as we know the dim of input, hyperparametes here is of choosing and rows is the no of tokens you have, we need this cause when\n",
        "# doing causal masking we mask over tokens so we need to know the no of token inorder to make tensor for our masking.\n",
        "model = CausalAttention(3,hyperparamter,6)\n",
        "attn = model(inputs)"
      ],
      "metadata": {
        "id": "rPgpsBJ8ZzWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw7fppXcZ7zs",
        "outputId": "f5a2c5cb-0435-49e0-ff99-a06bee1f1cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3423, -0.0886, -0.1723, -0.2687],\n",
              "        [ 0.3337, -0.0659, -0.0720, -0.2820],\n",
              "        [ 0.3267, -0.0631, -0.0420, -0.2772],\n",
              "        [ 0.2912, -0.0412, -0.0169, -0.2626],\n",
              "        [ 0.2305, -0.0922, -0.0348, -0.1460],\n",
              "        [ 0.2547, -0.0402, -0.0028, -0.2251]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self,idim,odim,context_length,num_heads,bias=False):\n",
        "    super().__init__()\n",
        "    self.odim = odim\n",
        "    self.num_head = num_heads\n",
        "    self.head_dim = odim // self.num_head\n",
        "\n",
        "    self.W_Q = nn.Linear(idim,odim,bias=False)\n",
        "    self.W_K = nn.Linear(idim,odim,bias=False)\n",
        "    self.W_V = nn.Linear(idim,odim,bias=False)\n",
        "\n",
        "    self.register_buffer('mask',torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
        "    self.out_proj = nn.Linear(odim,odim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    batch, num_row, feature_dim = x.shape\n",
        "\n",
        "    self.K = self.W_K(x)\n",
        "    self.Q = self.W_Q(x)\n",
        "    self.V = self.W_V(x)\n",
        "\n",
        "    # crucial step for mha, we are using non overlapping embedding dim for each of the token\n",
        "    self.K = self.K.view(batch,num_row,self.num_head,self.head_dim)\n",
        "    self.Q = self.Q.view(batch,num_row,self.num_head,self.head_dim)\n",
        "    self.V = self.V.view(batch,num_row,self.num_head,self.head_dim)\n",
        "\n",
        "    self.K = self.K.transpose(1,2)\n",
        "    self.Q = self.Q.transpose(1,2)\n",
        "    self.V = self.V.transpose(1,2)\n",
        "\n",
        "    # attn_score would always be of the num row length since we are working with batches we need all the tokens which come from rows\n",
        "    attn_score = self.K @ self.Q.transpose(2,3)\n",
        "    attn_score.masked_fill_(self.mask.bool()[:num_row,:num_row],-torch.inf)\n",
        "    attn_weight = torch.softmax(attn_score / self.K.shape[-1]**0.5, dim=-1)\n",
        "    context_vector = attn_weight @ self.V\n",
        "    context_vector = context_vector.contiguous().view(batch,num_row,self.odim)\n",
        "    # this out_proj is just here to get genrate these nuance in your multiple context vector so its kinda linear transformation of weights\n",
        "    # to combine the informatino across the heads you need to perform this operation so the heads can talk to each other.\n",
        "    context_vector = self.out_proj(context_vector)\n",
        "\n",
        "    # out_projection = self.out_proj(batch,num_row,self.odim)\n",
        "    return context_vector"
      ],
      "metadata": {
        "id": "NZTqgda7b0aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xy-4ehS3zMU",
        "outputId": "2441435e-4a6c-48b3-c751-cb88cb100241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idim = batch.shape[-1]\n",
        "hyperparameter = 4\n",
        "odim = hyperparameter\n",
        "context_length = batch.shape[1]\n",
        "num_heads = 2"
      ],
      "metadata": {
        "id": "Zz5Yr3hD4J68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiHeadAttention(idim, odim, context_length, num_heads)"
      ],
      "metadata": {
        "id": "by0j-vIk3qzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG_vYclk8JO8",
        "outputId": "7f8fca25-6816-4f12-935e-361c7d46cf7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0356, -0.3241,  0.3343, -0.1556],\n",
              "         [ 0.0788, -0.3076,  0.4104, -0.2109],\n",
              "         [ 0.0801, -0.3135,  0.4274, -0.2323],\n",
              "         [-0.0978, -0.5183,  0.2747, -0.4525],\n",
              "         [-0.1148, -0.5278,  0.3900, -0.5336],\n",
              "         [-0.1275, -0.5350,  0.3865, -0.5371]],\n",
              "\n",
              "        [[-0.0356, -0.3241,  0.3343, -0.1556],\n",
              "         [ 0.0788, -0.3076,  0.4104, -0.2109],\n",
              "         [ 0.0801, -0.3135,  0.4274, -0.2323],\n",
              "         [-0.0978, -0.5183,  0.2747, -0.4525],\n",
              "         [-0.1148, -0.5278,  0.3900, -0.5336],\n",
              "         [-0.1275, -0.5350,  0.3865, -0.5371]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZzW9PY-_8eT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}