{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN54M/mde7hVqPbZJHLOvTW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badBrock/MultiHeadAttentionJourney/blob/main/Preprocessing_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9FMHmKUT_9An"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "if not os.path.exists(\"the-verdict.txt\"):\n",
        "    url = (\n",
        "        \"https://raw.githubusercontent.com/rasbt/\"\n",
        "        \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "        \"the-verdict.txt\"\n",
        "    )\n",
        "    file_path = \"the-verdict.txt\"\n",
        "\n",
        "    response = requests.get(url, timeout=30)\n",
        "    response.raise_for_status()\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        f.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GHBZrEVA8NG",
        "outputId": "a7c89650-a82f-411d-dbd7-5c0ead9585df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)"
      ],
      "metadata": {
        "id": "vrwxLfYxD2H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "removed = [item for item in preprocessed if not item.strip()]\n",
        "removed[10:100:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB20nCMvGbfC",
        "outputId": "5c0d41d2-2e7f-4bac-ce4e-2ee027ed6055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ', ' ', '', ' ', ' ', ' ', ' ', ' ', ' ']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2wsOQfeD7k2",
        "outputId": "dbd96264-ad0b-4625-c77b-23982601ca55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEfyfOOyD-yp",
        "outputId": "b085c2da-f1f9-417c-96e1-e3a771374d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {num:words for words,num in enumerate(all_words)}"
      ],
      "metadata": {
        "id": "4CD2UYqgEN9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec = {i:j for j,i in vocab.items()}"
      ],
      "metadata": {
        "id": "dpiZhaJFFoM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(vocab.items()):\n",
        "    print(item)\n",
        "    if i >= 10:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw7y762nEcA6",
        "outputId": "a6af6841-8afb-4fc1-fc7a-e65a188fa29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = [vocab[i] for i in all_words]"
      ],
      "metadata": {
        "id": "YKx6ieMXE2nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ' '.join([dec[i] for i in [156,22,34]])\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4oUqjgJmFXIn",
        "outputId": "839243c8-e7b4-4f7f-885e-938d957cbe87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'an But Florence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class tokenizer:\n",
        "  def __init__(self,vocab):\n",
        "    self.t_to_int = vocab\n",
        "    self.int_to_t = {i:j for j,i in self.t_to_int.items()}\n",
        "\n",
        "  def encoder(self,x):\n",
        "    preprocessing = re.split(r'([,.:;?_!\"()\\']|--|\\s)', x)\n",
        "    preprocessing = [item.strip() for item in preprocessing if item.strip()]\n",
        "    preprocessing = [\n",
        "            item if item in self.t_to_int\n",
        "            else \"<|unk|>\" for item in preprocessing\n",
        "            ]\n",
        "    return [self.t_to_int[i] for i in preprocessing]\n",
        "\n",
        "  def decoder(self,x):\n",
        "    text = \" \".join([self.int_to_t[i] for i in x])\n",
        "    text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "JKjQdFBPFhd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = tokenizer(vocab)"
      ],
      "metadata": {
        "id": "FwBtwUD7JSsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = token.encoder('what the are you talking about my')"
      ],
      "metadata": {
        "id": "PjigL2QYJV8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.decoder(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AOPs6GYMJcfS",
        "outputId": "e53f813a-e7cf-410a-c7dc-c767f3dc918e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what the are you talking about my'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch"
      ],
      "metadata": {
        "id": "pMlJ7G2gN8ro"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDataLoader():\n",
        "  def __init__(self,text,tokenizer,context_length,stride):\n",
        "    self.inp = []\n",
        "    self.out = []\n",
        "\n",
        "    token_id = tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0,len(token_id)-context_length,stride):\n",
        "      inpu = token_id[i:i+context_length]\n",
        "      outp = token_id[i+1:i+context_length+1]\n",
        "      self.inp.append(torch.tensor(inpu))\n",
        "      self.out.append(torch.tensor(outp))\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.inp)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "      return self.inp[idx], self.out[idx]"
      ],
      "metadata": {
        "id": "miIf60H5MwJ-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def dataloader(text,batch,context_length,stride,shuffle=True, drop_last=True, num_workers=0):\n",
        "  get_token = tiktoken.get_encoding('gpt2')\n",
        "\n",
        "  dataset = GPTDataLoader(text,get_token,context_length,stride)\n",
        "#   data_load = DataLoader(\n",
        "#     dataset,\n",
        "#     batch_size=batch,\n",
        "#     shuffle=shuffle,\n",
        "#     drop_last=drop_last,\n",
        "#     num_workers=num_workers\n",
        "# )\n",
        "\n",
        "  data_load = DataLoader(\n",
        "     dataset,batch_size=batch, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers\n",
        "  )\n",
        "  return data_load"
      ],
      "metadata": {
        "id": "Ti-OVVTVNfdc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 8\n",
        "vocab = 50257 #depends on the dataset that you have\n",
        "context_length = 4\n",
        "output_dim = 128\n",
        "\n",
        "embedding = torch.nn.Embedding(vocab,output_dim)\n",
        "pos = torch.nn.Embedding(context_length,output_dim)\n",
        "\n",
        "load = dataloader(raw_text,batch,context_length,stride=context_length)"
      ],
      "metadata": {
        "id": "cCyT89hiP3Ku"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in load:\n",
        "  x,y = batch\n",
        "  token_embedding = embedding(x)\n",
        "  pos_embedding = pos(torch.arange(context_length))\n",
        "\n",
        "  input_embeddings = token_embedding + pos_embedding\n",
        "  break"
      ],
      "metadata": {
        "id": "wrm_-ym3QTWj"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI66wra1ReN-",
        "outputId": "0ce8823d-9705-4b16-b040-5252025e7766"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AemNbSXXULs3",
        "outputId": "605fd352-ae6c-4abf-cfc5-b42a83d18853"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1nvOKCmUOb8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}